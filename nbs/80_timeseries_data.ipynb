{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from fastai2.basics import *\n",
    "# from fastai2.data.all import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai2.data.external import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from zipfile import ZipFile "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Timeseries Data\n",
    "> Basic functions to read timeseries files like `.arff` and `.ts` files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@docs\n",
    "class TSData():\n",
    "    \"Class that loads .arff (soon .ts) files and returns a tuple (data.x , self.y)\"\n",
    "    \"self.x is a list of 2D array with a shape (n_samples, nb_channels, sequence_length) \"\n",
    "    \"self.y is a 1D array as y (i.e. label) with a shape (n_samples)\"\n",
    "    \"for the NATOPS_Train.arff file, the result will be : x(180, 24, 51) and y(180)\"\n",
    "    # def __init__(self):\n",
    "    #     self.x = self.y = self.dsname = self.fnames = [],[],[],[]\n",
    "    \n",
    "    def __init__(self, fnames, has_targets=True, fill_missing='NaN'):\n",
    "        # self.x = self.y = self.dsname = [],[],[]\n",
    "        self.x = []\n",
    "        self.y = []\n",
    "        self.dsname = []\n",
    "        self.fnames = fnames\n",
    "        self.has_targets = has_targets\n",
    "        self.fill_missings = fill_missing\n",
    "    \n",
    "    def __repr__(self): return f\"{self.__class__.__name__}:\\n Datasets names (concatenated): {self.dsname}\\n Filenames:                     {self.fnames}\\n Data shape: {self.x.shape}\\n Targets shape: {self.y.shape}\\n Nb Samples: {self.x.shape[0]}\\n Nb Channels:           {self.x.shape[1]}\\n Sequence Length: {self.x.shape[2]}\"\n",
    "    \n",
    "    def get_x(self, as_list=True): return(list(self.x))\n",
    "    def get_y(self): return(self.y)\n",
    "    def get_items(self): return [(item, str(label)) for (item, label) in zip(list(self.x), self.y)]\n",
    "    def __getitem__(self, i): return (self.x[i], str(self.y[i]))\n",
    "\n",
    "    @property\n",
    "    def sizes(self): return (self.x.shape, self.y.shape)\n",
    "    \n",
    "    @property\n",
    "    def n_channels(self): return (self.x.shape[1])\n",
    "    \n",
    "    def _load_arff(self, fname, has_targets=True, fill_missing='NaN'):\n",
    "        \"load an .arff file and return a tupple of 2 numpy arrays: \"\n",
    "        \"x : array with a shape (n_samples, nb_channels, sequence_length)\"\n",
    "        \"y : array with a shape (n_samples)\"\n",
    "        \"for the NATOPS_Train.arff  the result will be : x(180, 24, 51) and y(180)\"\n",
    "        \n",
    "        instance_list = []\n",
    "        class_val_list = []\n",
    "        data_started = False\n",
    "        is_multi_variate = False\n",
    "        is_first_case = True\n",
    "        \n",
    "        with open(fname, 'r') as f:\n",
    "            for line in f:\n",
    "                if line.strip():\n",
    "                    if is_multi_variate is False and \"@attribute\" in line.lower() and \"relational\" in line.lower():\n",
    "                        is_multi_variate = True\n",
    "                    if \"@data\" in line.lower():\n",
    "                        data_started = True\n",
    "                        continue\n",
    "                    # if the 'data tag has been found, the header information has been cleared and now data can be loaded\n",
    "                    if data_started:\n",
    "                        line = line.replace(\"?\", fill_missing)\n",
    "                        if is_multi_variate:\n",
    "                            if has_targets:\n",
    "                                line, class_val = line.split(\"',\")\n",
    "                                class_val_list.append(class_val.strip())\n",
    "                            dimensions = line.split(\"\\\\n\")\n",
    "                            dimensions[0] = dimensions[0].replace(\"'\", \"\")\n",
    "\n",
    "                            if is_first_case:\n",
    "                                for d in range(len(dimensions)):\n",
    "                                    instance_list.append([])\n",
    "                                is_first_case = False\n",
    "\n",
    "                            for dim in range(len(dimensions)):\n",
    "                                instance_list[dim].append(np.array(dimensions[dim].split(','), dtype=np.float32))\n",
    "#                                 instance_list[dim].append(np.fromiter(dimensions[dim].split(','), dtype=np.float32))\n",
    "                        else:\n",
    "                            if is_first_case:\n",
    "                                instance_list.append([])\n",
    "                                is_first_case = False\n",
    "\n",
    "                            line_parts = line.split(\",\")\n",
    "\n",
    "                            if has_targets:\n",
    "                                instance_list[0].append(np.array(line_parts[:len(line_parts)-1], dtype=np.float32))\n",
    "\n",
    "                                class_val_list.append(line_parts[-1].strip())\n",
    "                            else:\n",
    "                                instance_list[0].append(np.array(line_parts[:len(line_parts)-1], dtype=np.float32))\n",
    "\n",
    "        #instance_list has a shape of (dimensions, nb_samples, seq_lenght)\n",
    "        #for the NATOPS_Train.arff it would be (24, 180, 51)\n",
    "        #convert python list to numpy array and transpose the 2 first dimensions -> (180, 24, 51)\n",
    "        x = np.asarray(instance_list).transpose(1,0,2) \n",
    "        \n",
    "        if has_targets:\n",
    "            y = np.asarray(class_val_list)       \n",
    "            return x, y\n",
    "        else:\n",
    "            return x, [None*x.shape[0]]\n",
    "\n",
    "    @classmethod\n",
    "    def from_arff(self, fnames, has_targets=True, fill_missing='NaN'):\n",
    "        \"load an .arff file and return a tupple of 2 numpy arrays: \"\n",
    "        \"x : array with a shape (n_samples, nb_channels, sequence_length)\"\n",
    "        \"y : array with a shape (n_samples)\"\n",
    "        \"for the NATOPS_Train.arff  the result will be : x(180, 24, 51) and y(180)\"\n",
    "        data = self(fnames, has_targets=has_targets, fill_missing=fill_missing)\n",
    "        if isinstance(fnames, list):\n",
    "            data.x = []\n",
    "            data.y = []\n",
    "            data.dsname = []\n",
    "            data.fnames = []\n",
    "            xs,ys = [],[]\n",
    "            for i, fn in enumerate(fnames):\n",
    "                x,y = data._load_arff(fn, has_targets=has_targets, fill_missing=fill_missing)\n",
    "                xs.append(x)\n",
    "                ys.append(y)\n",
    "                data.fnames.append(fn)\n",
    "                data.dsname.append(fn.stem)\n",
    "            data.x = np.concatenate(xs)\n",
    "            data.y = np.concatenate(ys)\n",
    "        else:\n",
    "            data.fnames.append(fnames)\n",
    "            data.dsname.append(fnames.stem)\n",
    "            data.x, data.y = data._load(fnames, has_targets=has_targets, fill_missing=fill_missing)\n",
    "\n",
    "        return data\n",
    "\n",
    "# add_docs(TSData,\n",
    "#          from_arff=\"read one or serveral arff files and concatenate them, and returns a TSData object\")\n",
    "\n",
    "    _docs=dict(\n",
    "         from_arff=\"read one or serveral arff files and concatenate them, and returns a TSData object\",\n",
    "         get_items=\"return list of tuples. Each tuple corresponds to a timeserie (nump.ndarray) and a label (string)\",\n",
    "         get_x=\"return list of timeseries (no labels)\",\n",
    "         get_y=\"return list of labels corresponding to each timeserie\",\n",
    "         sizes=\"return timeseries shape and labels shape (labels list size)\",\n",
    "         n_channels=\"return timeserie's number of channels. For `arff` files it is called `dimension`. In the case of NATOPS_Train.arff, it returns 24\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": "<h4 id=\"TSData.from_arff\" class=\"doc_header\"><code>TSData.from_arff</code><a href=\"__main__.py#L96\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n\n> <code>TSData.from_arff</code>(**`fnames`**, **`has_targets`**=*`True`*, **`fill_missing`**=*`'NaN'`*)\n\nread one or serveral arff files and concatenate them, and returns a TSData object",
      "text/plain": "<IPython.core.display.Markdown object>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(TSData.from_arff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": "<h4 id=\"TSData.get_items\" class=\"doc_header\"><code>TSData.get_items</code><a href=\"__main__.py#L24\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n\n> <code>TSData.get_items</code>()\n\nreturn list of tuples. Each tuple corresponds to a timeserie (nump.ndarray) and a label (string)",
      "text/plain": "<IPython.core.display.Markdown object>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(TSData.get_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": "<h4 id=\"TSData.n_channels\" class=\"doc_header\"><code>TSData.n_channels</code><a href=\"\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n\nreturn timeserie's number of channels. For `arff` files it is called `dimension`. In the case of NATOPS_Train.arff, it returns 24",
      "text/plain": "<IPython.core.display.Markdown object>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(TSData.n_channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_ts_items(fnames):\n",
    "    'get_ts_items return list of tuples. Each tuple corresponds to a timeserie (nump.ndarray) and a label (string)'\n",
    "    data = TSData.from_arff(fnames)\n",
    "    return data.get_items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": "<h4 id=\"get_ts_items\" class=\"doc_header\"><code>get_ts_items</code><a href=\"__main__.py#L2\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n\n> <code>get_ts_items</code>(**`fnames`**)\n\nget_ts_items return list of tuples. Each tuple corresponds to a timeserie (nump.ndarray) and a label (string)",
      "text/plain": "<IPython.core.display.Markdown object>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(get_ts_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": "<h4 id=\"get_ts_items\" class=\"doc_header\"><code>get_ts_items</code><a href=\"__main__.py#L2\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n\n> <code>get_ts_items</code>(**`fnames`**)\n\nget_ts_items return list of tuples. Each tuple corresponds to a timeserie (nump.ndarray) and a label (string)",
      "text/plain": "<IPython.core.display.Markdown object>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(get_ts_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_ext(fnames, ext):\n",
    "        if isinstance(fnames, list):\n",
    "            fnames = [fn if (fn.suffix!='') else f'{fn}.{ext}' for fn in fnames] \n",
    "        else:\n",
    "            fnames = fnames if (fnames.suffix!='') else f'{fnames}.{ext}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Timeseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def show_timeseries(ts, ctx=None, title=None, chs=None, leg=True, **kwargs):\n",
    "    \"\"\"\n",
    "    Plot a timeseries.\n",
    "\n",
    "    Args:\n",
    "\n",
    "        title : usually the class of the timeseries \n",
    "\n",
    "        ts : timeseries. It should have a shape of (nb_channels, sequence_length)\n",
    "\n",
    "        chs : array representing a list of channels to plot \n",
    "\n",
    "        leg : Display or not a legend\n",
    "    \"\"\"\n",
    "\n",
    "    if ctx is None: fig, ctx = plt.subplots()\n",
    "    t = range(ts.shape[1])\n",
    "    chs_max = max(chs) if chs else 0\n",
    "    channels = chs if (chs and (chs_max < ts.shape[0])) else range(ts.shape[0]) \n",
    "    for ch in channels:\n",
    "        ctx.plot(t, ts[ch], label='ch'+str(ch))\n",
    "    if leg: ctx.legend(loc='upper right', ncol=2, framealpha=0.5)\n",
    "    if title: ctx.set_title(title)\n",
    "    return ctx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": "<h4 id=\"show_timeseries\" class=\"doc_header\"><code>show_timeseries</code><a href=\"__main__.py#L2\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n\n> <code>show_timeseries</code>(**`ts`**, **`ctx`**=*`None`*, **`title`**=*`None`*, **`chs`**=*`None`*, **`leg`**=*`True`*, **\\*\\*`kwargs`**)\n\nPlot a timeseries.\n\nArgs:\n\n    title : usually the class of the timeseries \n\n    ts : timeseries. It should have a shape of (nb_channels, sequence_length)\n\n    chs : array representing a list of channels to plot \n\n    leg : Display or not a legend",
      "text/plain": "<IPython.core.display.Markdown object>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(show_timeseries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "Path('/home/farid/.fastai/data')"
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_data = Config().data\n",
    "path_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def file_extract_at_filename(fname, dest):\n",
    "    \"Extract `fname` to `dest`/`fname`.name folder using `tarfile` or `zipfile\" \n",
    "    dest = Path(dest)/Path(fname).with_suffix('').name\n",
    "    # tarfile.open(fname, 'r:gz').extractall(dest)\n",
    "    fname = str(fname)\n",
    "    if   fname.endswith('gz'):  tarfile.open(fname, 'r:gz').extractall(dest)\n",
    "    elif fname.endswith('zip'): zipfile.ZipFile(fname     ).extractall(dest)\n",
    "    else: raise Exception(f'Unrecognized archive: {fname}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`file_extract_at_filename` is used by default in `unzip_data` to decompress the downloaded file in a folder that has the same name as the zip filename."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def unzip_data(url, fname=None, dest=None, c_key='data', force_download=False):\n",
    "    \"Download `url` to `fname` if `dest` doesn't exist, and un-compress to `dest`/`fname`.name folder .\"\n",
    "    return untar_data(url, fname=fname, c_key=c_key, force_download=force_download, extract_func=file_extract_at_filename)    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`unzip_data` download and decompress the downloaded file in a folder and decompress it in a folder that has the same name as the zip filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": "<h4 id=\"unzip_data\" class=\"doc_header\"><code>unzip_data</code><a href=\"__main__.py#L2\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n\n> <code>unzip_data</code>(**`url`**, **`fname`**=*`None`*, **`dest`**=*`None`*, **`c_key`**=*`'data'`*, **`force_download`**=*`False`*)\n\nDownload `url` to `fname` if `dest` doesn't exist, and un-compress to `dest`/`fname`.name folder .",
      "text/plain": "<IPython.core.display.Markdown object>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(unzip_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class URLs_TS():\n",
    "    \"Global constants for dataset and model URLs.\"\n",
    "    LOCAL_PATH = Path.cwd()\n",
    "    URL = 'http://www.timeseriesclassification.com/Downloads/'\n",
    "\n",
    "\n",
    "    # UCRmultivariate datasets\n",
    "    ARTICULARY_WORD_RECOGNITION   = f'{URL}ArticularyWordRecognition.zip'\n",
    "    ATRIAL_FIBRILLATION           = f'{URL}AtrialFibrillation.zip'\n",
    "    BASIC_MOTIONS                 = f'{URL}BasicMotions.zip'\n",
    "    CHARACTER_TRAJECTORIES        = f'{URL}CharacterTrajectories.zip'\n",
    "    CRICKET                       = f'{URL}Cricket.zip'\n",
    "    DUCK_DUCK_GEESE               = f'{URL}DuckDuckGeese.zip'\n",
    "    EIGEN_WORMS                   = f'{URL}EigenWorms.zip'\n",
    "    EPILEPSY                      = f'{URL}Epilepsy.zip'\n",
    "    ETHANOL_CONCENTRATION         = f'{URL}EthanolConcentration.zip'\n",
    "    ERING                        = f'{URL}ERing.zip'\n",
    "    FACE_DETECTION                = f'{URL}FaceDetection.zip'\n",
    "    FINGER_MOVEMENTS              = f'{URL}FingerMovements.zip'\n",
    "    HAND_MOVEMENT_DIRECTION       = f'{URL}HandMovementDirection.zip'\n",
    "    HANDWRITING                   = f'{URL}Handwriting.zip'\n",
    "    HEARTBEAT                     = f'{URL}Heartbeat.zip'\n",
    "    JAPANESE_VOWELS               = f'{URL}JapaneseVowels.zip'\n",
    "    LIBRAS                        = f'{URL}Libras.zip'\n",
    "    LSST                          = f'{URL}LSST.zip'\n",
    "    INSECT_WINGBEAT               = f'{URL}InsectWingbeat.zip'\n",
    "    MOTOR_IMAGERY                 = f'{URL}MotorImagery.zip'\n",
    "    NATOPS                        = f'{URL}NATOPS.zip'\n",
    "    PEN_DIGITS                    = f'{URL}PenDigits.zip'\n",
    "    PEMS_SF                       = f'{URL}PEMS-SF.zip'\n",
    "    PHONEME_SPECTRA               = f'{URL}PhonemeSpectra.zip'\n",
    "    RACKET_SPORTS                 = f'{URL}RacketSports.zip'\n",
    "    SELF_REGULATION_SCP1          = f'{URL}SelfRegulationSCP1.zip'\n",
    "    SELF_REGULATION_SCP2          = f'{URL}SelfRegulationSCP2.zip'\n",
    "    SPOKEN_ARABIC_DIGITS          = f'{URL}SpokenArabicDigits.zip'\n",
    "    STAND_WALK_JUMP               = f'{URL}StandWalkJump.zip'\n",
    "    UWAVE_GESTURE_LIBRARY        = f'{URL}UWaveGestureLibrary.zip'\n",
    "\n",
    "    def path(url='.', c_key='archive'):\n",
    "        fname = url.split('/')[-1]\n",
    "        local_path = URLs.LOCAL_PATH/('models' if c_key=='models' else 'data')/fname\n",
    "        if local_path.exists(): return local_path\n",
    "        return Config()[c_key]/fname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsname =  'NATOPS' #'NATOPS', 'LSST', 'Wine', 'Epilepsy', 'HandMovementDirection'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "Path('/home/farid/.fastai/data/NATOPS')"
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = unzip_data(URLs_TS.NATOPS)\n",
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "(#54) [Path('/home/farid/.fastai/data/NATOPS/NATOPS.jpg'),Path('/home/farid/.fastai/data/NATOPS/NATOPS.txt'),Path('/home/farid/.fastai/data/NATOPS/NATOPSDimension10_TEST.arff'),Path('/home/farid/.fastai/data/NATOPS/NATOPSDimension10_TRAIN.arff'),Path('/home/farid/.fastai/data/NATOPS/NATOPSDimension11_TEST.arff'),Path('/home/farid/.fastai/data/NATOPS/NATOPSDimension11_TRAIN.arff'),Path('/home/farid/.fastai/data/NATOPS/NATOPSDimension12_TEST.arff'),Path('/home/farid/.fastai/data/NATOPS/NATOPSDimension12_TRAIN.arff'),Path('/home/farid/.fastai/data/NATOPS/NATOPSDimension13_TEST.arff'),Path('/home/farid/.fastai/data/NATOPS/NATOPSDimension13_TRAIN.arff')...]"
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path.ls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "[Path('/home/farid/.fastai/data/NATOPS/NATOPS_TRAIN.arff'),\n Path('/home/farid/.fastai/data/NATOPS/NATOPS_TEST.arff')]"
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fname_train = f'{dsname}_TRAIN.arff'\n",
    "fname_test = f'{dsname}_TEST.arff'\n",
    "fnames = [path/fname_train, path/fname_test]\n",
    "fnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "TSData:\n Datasets names (concatenated): ['NATOPS_TRAIN', 'NATOPS_TEST']\n Filenames:                     [Path('/home/farid/.fastai/data/NATOPS/NATOPS_TRAIN.arff'), Path('/home/farid/.fastai/data/NATOPS/NATOPS_TEST.arff')]\n Data shape: (360, 24, 51)\n Targets shape: (360,)\n Nb Samples: 360\n Nb Channels:           24\n Sequence Length: 51"
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = TSData.from_arff(fnames)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "TSData:\n Datasets names (concatenated): ['NATOPS_TRAIN', 'NATOPS_TEST']\n Filenames:                     [Path('/home/farid/.fastai/data/NATOPS/NATOPS_TRAIN.arff'), Path('/home/farid/.fastai/data/NATOPS/NATOPS_TEST.arff')]\n Data shape: (360, 24, 51)\n Targets shape: (360,)\n Nb Samples: 360\n Nb Channels:           24\n Sequence Length: 51\n"
    }
   ],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "(['NATOPS_TRAIN', 'NATOPS_TEST'],\n [Path('/home/farid/.fastai/data/NATOPS/NATOPS_TRAIN.arff'),\n  Path('/home/farid/.fastai/data/NATOPS/NATOPS_TEST.arff')],\n 24,\n ((360, 24, 51), (360,)),\n (360, 24, 51),\n (360,))"
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dsname, data.fnames, data.n_channels, data.sizes, data.x.shape, data.y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(data.dsname, ['NATOPS_TRAIN', 'NATOPS_TEST'])\n",
    "test_eq(data.n_channels, 24)\n",
    "test_eq(data.sizes, ((360, 24, 51), (360,)))\n",
    "test_eq(data.x.shape, (360, 24, 51))\n",
    "test_eq(data.y.shape, (360,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "(numpy.ndarray,\n array([[-0.54737 , -0.546334, -0.549748, ..., -0.533726, -0.528338,\n         -0.518618],\n        [-1.600105, -1.599419, -1.595734, ..., -1.576063, -1.572246,\n         -1.565955],\n        [-0.809446, -0.80942 , -0.812398, ..., -0.766209, -0.764902,\n         -0.765835],\n        ...,\n        [ 0.618919,  0.648665,  0.618913, ...,  0.455396,  0.457002,\n          0.456688],\n        [-1.497652, -1.465919, -1.50323 , ..., -1.435609, -1.422537,\n         -1.421817],\n        [-0.754927, -0.706829, -0.758939, ..., -0.538306, -0.530174,\n         -0.529384]], dtype=float32))"
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(data.get_items()[1][0]), data.get_items()[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "(numpy.str_, '3.0')"
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(data.get_y()[1]), data.get_y()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(data.get_y()[1], '3.0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# idx = 4\n",
    "# ts, title = train_x[idx], train_y[idx]\n",
    "# show_timeseries(ts, title=title, chs=range(0,24,3)) \n",
    "# # show_timeseries(ts, title=title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show_timeseries(ts, title=title, chs=[2]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read '.ts' file into 3D array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_from_tsfile_to_array(full_file_path_and_name, return_separate_X_and_y=True, replace_missing_vals_with='NaN'):\n",
    "    \"\"\"Loads data from a .ts file into a Pandas DataFrame.\n",
    "\n",
    "    Parameters\n",
    "    full_file_path_and_name: str\n",
    "        The full pathname of the .ts file to read.\n",
    "    return_separate_X_and_y: bool\n",
    "        true if X and Y values should be returned as separate Data Frames (X) and a numpy array (y), false otherwise.\n",
    "        This is only relevant for data that\n",
    "    replace_missing_vals_with: str\n",
    "       The value that missing values in the text file should be replaced with prior to parsing.\n",
    "\n",
    "    Returns\n",
    "    DataFrame, ndarray\n",
    "        If return_separate_X_and_y then a tuple containing a DataFrame and a numpy array containing the relevant time-series and            corresponding class values.\n",
    "    DataFrame\n",
    "        If not return_separate_X_and_y then a single DataFrame containing all time-series and (if relevant) a column \"class_vals\"           the associated class values.\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize flags and variables used when parsing the file\n",
    "\n",
    "    metadata_started = False\n",
    "    data_started = False\n",
    "\n",
    "    has_problem_name_tag = False\n",
    "    has_timestamps_tag = False\n",
    "    has_univariate_tag = False\n",
    "    has_class_labels_tag = False\n",
    "    has_data_tag = False\n",
    "\n",
    "    previous_timestamp_was_int = None\n",
    "    previous_timestamp_was_timestamp = None\n",
    "    num_dimensions = None\n",
    "    is_first_case = True\n",
    "    instance_list = []\n",
    "    class_val_list = []\n",
    "    line_num = 0\n",
    "\n",
    "    # Parse the file\n",
    "    # print(full_file_path_and_name)\n",
    "    with open(full_file_path_and_name, 'r',encoding='utf-8') as file:\n",
    "        for line in file:\n",
    "            # Strip white space from start/end of line and change to lowercase for use below\n",
    "            line = line.strip().lower()\n",
    "            # Empty lines are valid at any point in a file\n",
    "            if line:\n",
    "                # Check if this line contains metadata\n",
    "                # Please note that even though metadata is stored in this function it is not currently published externally\n",
    "                if line.startswith(\"@problemname\"):\n",
    "                    # Check that the data has not started\n",
    "                    if data_started:\n",
    "                        raise TsFileParseException(\"metadata must come before data\")\n",
    "                    # Check that the associated value is valid\n",
    "                    tokens = line.split(' ')\n",
    "                    token_len = len(tokens)\n",
    "\n",
    "                    if token_len == 1:\n",
    "                        raise TsFileParseException(\"problemname tag requires an associated value\")\n",
    "\n",
    "                    problem_name = line[len(\"@problemname\") + 1:]\n",
    "                    has_problem_name_tag = True\n",
    "                    metadata_started = True\n",
    "\n",
    "                elif line.startswith(\"@timestamps\"):\n",
    "\n",
    "                    # Check that the data has not started\n",
    "\n",
    "                    if data_started:\n",
    "                        raise TsFileParseException(\"metadata must come before data\")\n",
    "\n",
    "                    # Check that the associated value is valid\n",
    "\n",
    "                    tokens = line.split(' ')\n",
    "                    token_len = len(tokens)\n",
    "\n",
    "                    if token_len != 2:\n",
    "                        raise TsFileParseException(\"timestamps tag requires an associated Boolean value\")\n",
    "\n",
    "                    elif tokens[1] == \"true\":\n",
    "                        timestamps = True\n",
    "\n",
    "                    elif tokens[1] == \"false\":\n",
    "                        timestamps = False\n",
    "\n",
    "                    else:\n",
    "                        raise TsFileParseException(\"invalid timestamps value\")\n",
    "\n",
    "                    has_timestamps_tag = True\n",
    "                    metadata_started = True\n",
    "\n",
    "                elif line.startswith(\"@univariate\"):\n",
    "\n",
    "                    # Check that the data has not started\n",
    "\n",
    "                    if data_started:\n",
    "                        raise TsFileParseException(\"metadata must come before data\")\n",
    "\n",
    "                    # Check that the associated value is valid\n",
    "\n",
    "                    tokens = line.split(' ')\n",
    "                    token_len = len(tokens)\n",
    "\n",
    "                    if token_len != 2:\n",
    "                        raise TsFileParseException(\"univariate tag requires an associated Boolean value\")\n",
    "\n",
    "                    elif tokens[1] == \"true\":\n",
    "                        univariate = True\n",
    "\n",
    "                    elif tokens[1] == \"false\":\n",
    "                        univariate = False\n",
    "\n",
    "                    else:\n",
    "                        raise TsFileParseException(\"invalid univariate value\")\n",
    "\n",
    "                    has_univariate_tag = True\n",
    "                    metadata_started = True\n",
    "\n",
    "                elif line.startswith(\"@classlabel\"):\n",
    "\n",
    "                    # Check that the data has not started\n",
    "\n",
    "                    if data_started:\n",
    "                        raise TsFileParseException(\"metadata must come before data\")\n",
    "\n",
    "                    # Check that the associated value is valid\n",
    "\n",
    "                    tokens = line.split(' ')\n",
    "                    token_len = len(tokens)\n",
    "\n",
    "                    if token_len == 1:\n",
    "                        raise TsFileParseException(\"classlabel tag requires an associated Boolean value\")\n",
    "\n",
    "                    if tokens[1] == \"true\":\n",
    "                        class_labels = True\n",
    "\n",
    "                    elif tokens[1] == \"false\":\n",
    "                        class_labels = False\n",
    "\n",
    "                    else:\n",
    "                        raise TsFileParseException(\"invalid classLabel value\")\n",
    "\n",
    "                    # Check if we have any associated class values\n",
    "\n",
    "                    if token_len == 2 and class_labels:\n",
    "                        raise TsFileParseException(\"if the classlabel tag is true then class values must be supplied\")\n",
    "\n",
    "                    has_class_labels_tag = True\n",
    "                    class_label_list = [token.strip() for token in tokens[2:]]\n",
    "                    metadata_started = True\n",
    "\n",
    "                # Check if this line contains the start of data\n",
    "\n",
    "                elif line.startswith(\"@data\"):\n",
    "\n",
    "                    if line != \"@data\":\n",
    "                        raise TsFileParseException(\"data tag should not have an associated value\")\n",
    "\n",
    "                    if data_started and not metadata_started:\n",
    "                        raise TsFileParseException(\"metadata must come before data\")\n",
    "\n",
    "                    else:\n",
    "                        has_data_tag = True\n",
    "                        data_started = True\n",
    "\n",
    "                # If the 'data tag has been found then metadata has been parsed and data can be loaded\n",
    "\n",
    "                elif data_started:\n",
    "\n",
    "                    # Check that a full set of metadata has been provided\n",
    "\n",
    "                    if (not has_problem_name_tag or not has_timestamps_tag or not has_univariate_tag \n",
    "                        or not has_class_labels_tag or not has_data_tag):\n",
    "                        raise TsFileParseException(\"a full set of metadata has not been provided before the data\")\n",
    "\n",
    "                    # Replace any missing values with the value specified\n",
    "\n",
    "                    line = line.replace(\"?\", replace_missing_vals_with)\n",
    "\n",
    "                    # Check if we dealing with data that has timestamps\n",
    "\n",
    "                    if timestamps:\n",
    "\n",
    "                        # We're dealing with timestamps so cannot just split line on ':' as timestamps may contain one\n",
    "\n",
    "                        has_another_value = False\n",
    "                        has_another_dimension = False\n",
    "\n",
    "                        timestamps_for_dimension = []\n",
    "                        values_for_dimension = []\n",
    "\n",
    "                        this_line_num_dimensions = 0\n",
    "                        line_len = len(line)\n",
    "                        char_num = 0\n",
    "\n",
    "                        while char_num < line_len:\n",
    "\n",
    "                            # Move through any spaces\n",
    "\n",
    "                            while char_num < line_len and str.isspace(line[char_num]):\n",
    "                                char_num += 1\n",
    "\n",
    "                            # See if there is any more data to read in or if we should validate that read thus far\n",
    "\n",
    "                            if char_num < line_len:\n",
    "\n",
    "                                # See if we have an empty dimension (i.e. no values)\n",
    "\n",
    "                                if line[char_num] == \":\":\n",
    "                                    if len(instance_list) < (this_line_num_dimensions + 1):\n",
    "                                        instance_list.append([])\n",
    "\n",
    "                                    instance_list[this_line_num_dimensions].append(pd.Series())\n",
    "                                    this_line_num_dimensions += 1\n",
    "\n",
    "                                    has_another_value = False\n",
    "                                    has_another_dimension = True\n",
    "\n",
    "                                    timestamps_for_dimension = []\n",
    "                                    values_for_dimension = []\n",
    "\n",
    "                                    char_num += 1\n",
    "\n",
    "                                else:\n",
    "\n",
    "                                    # Check if we have reached a class label\n",
    "\n",
    "                                    if line[char_num] != \"(\" and class_labels:\n",
    "\n",
    "                                        class_val = line[char_num:].strip()\n",
    "\n",
    "                                        if class_val not in class_label_list:\n",
    "                                            raise TsFileParseException(\"the class value '\" + class_val + \"' on line \" + \n",
    "                                            str(line_num + 1) + \" is not valid\")\n",
    "\n",
    "                                        class_val_list.append(class_val)\n",
    "                                        char_num = line_len\n",
    "\n",
    "                                        has_another_value = False\n",
    "                                        has_another_dimension = False\n",
    "\n",
    "                                        timestamps_for_dimension = []\n",
    "                                        values_for_dimension = []\n",
    "\n",
    "                                    else:\n",
    "\n",
    "                                        # Read in the data contained within the next tuple\n",
    "\n",
    "                                        if line[char_num] != \"(\" and not class_labels:\n",
    "                                            raise TsFileParseException(\"dimension \" + str(this_line_num_dimensions + 1) + \n",
    "                                                \" on line \" + str(line_num + 1) + \" does not start with a '('\")\n",
    "\n",
    "                                        char_num += 1\n",
    "                                        tuple_data = \"\"\n",
    "\n",
    "                                        while char_num < line_len and line[char_num] != \")\":\n",
    "                                            tuple_data += line[char_num]\n",
    "                                            char_num += 1\n",
    "\n",
    "                                        if char_num >= line_len or line[char_num] != \")\":\n",
    "                                            raise TsFileParseException(\"dimension \" + str(this_line_num_dimensions + 1) +\n",
    "                                            \" on line \" + str(line_num + 1) + \" does not end with a ')'\")\n",
    "\n",
    "                                        # Read in any spaces immediately after the current tuple\n",
    "\n",
    "                                        char_num += 1\n",
    "\n",
    "                                        while char_num < line_len and str.isspace(line[char_num]):\n",
    "                                            char_num += 1\n",
    "\n",
    "                                        # Check if there is another value or dimension to process after this tuple\n",
    "\n",
    "                                        if char_num >= line_len:\n",
    "                                            has_another_value = False\n",
    "                                            has_another_dimension = False\n",
    "\n",
    "                                        elif line[char_num] == \",\":\n",
    "                                            has_another_value = True\n",
    "                                            has_another_dimension = False\n",
    "\n",
    "                                        elif line[char_num] == \":\":\n",
    "                                            has_another_value = False\n",
    "                                            has_another_dimension = True\n",
    "\n",
    "                                        char_num += 1\n",
    "\n",
    "                                        # Get the numeric value for the tuple by reading from the end of the tuple data backwards                                               to the last comma\n",
    "\n",
    "                                        last_comma_index = tuple_data.rfind(',')\n",
    "\n",
    "                                        if last_comma_index == -1:\n",
    "                                            raise TsFileParseException(\"dimension \" + str(this_line_num_dimensions + 1) + \n",
    "                                            \" on line \" + str(line_num + 1) + \" contains a tuple that has no comma inside of it\")\n",
    "\n",
    "                                        try:\n",
    "                                            value = tuple_data[last_comma_index + 1:]\n",
    "                                            value = float(value)\n",
    "\n",
    "                                        except ValueError:\n",
    "                                            raise TsFileParseException(\"dimension \" + str(this_line_num_dimensions + 1) + \n",
    "                                            \" on line \" + str(line_num + 1) + \n",
    "                                            \" contains a tuple that does not have a valid numeric value\")\n",
    "\n",
    "                                        # Check the type of timestamp that we have\n",
    "\n",
    "                                        timestamp = tuple_data[0: last_comma_index]\n",
    "\n",
    "                                        try:\n",
    "                                            timestamp = int(timestamp)\n",
    "                                            timestamp_is_int = True\n",
    "                                            timestamp_is_timestamp = False\n",
    "\n",
    "                                        except ValueError:\n",
    "                                            timestamp_is_int = False\n",
    "\n",
    "                                        if not timestamp_is_int:\n",
    "                                            try:\n",
    "                                                timestamp = timestamp.strip()\n",
    "                                                timestamp_is_timestamp = True\n",
    "\n",
    "                                            except ValueError:\n",
    "                                                timestamp_is_timestamp = False\n",
    "\n",
    "                                        # Make sure that the timestamps in the file (not just this dimension or case) are consistent\n",
    "\n",
    "                                        if not timestamp_is_timestamp and not timestamp_is_int:\n",
    "                                            raise TsFileParseException(\"dimension \" + str(this_line_num_dimensions + 1) + \n",
    "                                            \" on line \" + str(line_num + 1) + \" contains a tuple that has an invalid timestamp '\" + \n",
    "                                            timestamp + \"'\")\n",
    "\n",
    "                                        if previous_timestamp_was_int is not None and previous_timestamp_was_int and \\\n",
    "                                         not timestamp_is_int:\n",
    "                                            raise TsFileParseException(\"dimension \" + str(this_line_num_dimensions + 1) + \n",
    "                                            \" on line \" + str(line_num + 1) + \n",
    "                                            \" contains tuples where the timestamp format is inconsistent\")\n",
    "\n",
    "                                        if previous_timestamp_was_timestamp is not None and previous_timestamp_was_timestamp and \\\n",
    "                                        not timestamp_is_timestamp:\n",
    "                                            raise TsFileParseException(\"dimension \" + str(this_line_num_dimensions + 1) +\n",
    "                                            \" on line \" + str(line_num + 1) + \n",
    "                                            \" contains tuples where the timestamp format is inconsistent\")\n",
    "\n",
    "                                        # Store the values\n",
    "\n",
    "                                        timestamps_for_dimension += [timestamp]\n",
    "                                        values_for_dimension += [value]\n",
    "\n",
    "                                        #  If this was our first tuple then we store the type of timestamp we had\n",
    "\n",
    "                                        if previous_timestamp_was_timestamp is None and timestamp_is_timestamp:\n",
    "                                            previous_timestamp_was_timestamp = True\n",
    "                                            previous_timestamp_was_int = False\n",
    "\n",
    "                                        if previous_timestamp_was_int is None and timestamp_is_int:\n",
    "                                            previous_timestamp_was_timestamp = False\n",
    "                                            previous_timestamp_was_int = True\n",
    "\n",
    "                                        # See if we should add the data for this dimension\n",
    "\n",
    "                                        if not has_another_value:\n",
    "                                            if len(instance_list) < (this_line_num_dimensions + 1):\n",
    "                                                instance_list.append([])\n",
    "\n",
    "                                            if timestamp_is_timestamp:\n",
    "                                                timestamps_for_dimension = pd.DatetimeIndex(timestamps_for_dimension)\n",
    "\n",
    "                                            instance_list[this_line_num_dimensions].append(pd.Series(index=timestamps_for_dimension\n",
    "                                            , data=values_for_dimension))\n",
    "                                            this_line_num_dimensions += 1\n",
    "\n",
    "                                            timestamps_for_dimension = []\n",
    "                                            values_for_dimension = []\n",
    "\n",
    "                            elif has_another_value:\n",
    "                                raise TsFileParseException(\"dimension \" + str(this_line_num_dimensions + 1) + \n",
    "                                \" on line \" + str(line_num + 1) + \" ends with a ',' that is not followed by another tuple\")\n",
    "\n",
    "                            elif has_another_dimension and class_labels:\n",
    "                                raise TsFileParseException(\"dimension \" + str(this_line_num_dimensions + 1) + \n",
    "                                \" on line \" + str(line_num + 1) + \" ends with a ':' while it should list a class value\")\n",
    "\n",
    "                            elif has_another_dimension and not class_labels:\n",
    "                                if len(instance_list) < (this_line_num_dimensions + 1):\n",
    "                                    instance_list.append([])\n",
    "\n",
    "                                instance_list[this_line_num_dimensions].append(pd.Series(dtype=np.float32))\n",
    "                                this_line_num_dimensions += 1\n",
    "                                num_dimensions = this_line_num_dimensions\n",
    "\n",
    "                            # If this is the 1st line of data we have seen then note the dimensions\n",
    "\n",
    "                            if not has_another_value and not has_another_dimension:\n",
    "                                if num_dimensions is None:\n",
    "                                    num_dimensions = this_line_num_dimensions\n",
    "\n",
    "                                if num_dimensions != this_line_num_dimensions:\n",
    "                                    raise TsFileParseException(\"line \" + str(line_num + 1) + \n",
    "                                    \" does not have the same number of dimensions as the previous line of data\")\n",
    "\n",
    "                        # Check that we are not expecting some more data, and if not, store that processed above\n",
    "\n",
    "                        if has_another_value:\n",
    "                            raise TsFileParseException(\"dimension \" + str(this_line_num_dimensions + 1) + \n",
    "                            \" on line \" + str(line_num + 1) + \" ends with a ',' that is not followed by another tuple\")\n",
    "\n",
    "                        elif has_another_dimension and class_labels:\n",
    "                            raise TsFileParseException(\"dimension \" + str(this_line_num_dimensions + 1) + \n",
    "                            \" on line \" + str(line_num + 1) + \" ends with a ':' while it should list a class value\")\n",
    "\n",
    "                        elif has_another_dimension and not class_labels:\n",
    "                            if len(instance_list) < (this_line_num_dimensions + 1):\n",
    "                                instance_list.append([])\n",
    "\n",
    "                            instance_list[this_line_num_dimensions].append(pd.Series())\n",
    "                            this_line_num_dimensions += 1\n",
    "                            num_dimensions = this_line_num_dimensions\n",
    "\n",
    "                        # If this is the 1st line of data we have seen then note the dimensions\n",
    "\n",
    "                        if not has_another_value and num_dimensions != this_line_num_dimensions:\n",
    "                            raise TsFileParseException(\"line \" + str(line_num + 1) + \n",
    "                            \" does not have the same number of dimensions as the previous line of data\")\n",
    "\n",
    "                        # Check if we should have class values, and if so that they are contained in those listed in the metadata\n",
    "\n",
    "                        if class_labels and len(class_val_list) == 0:\n",
    "                            raise TsFileParseException(\"the cases have no associated class values\")\n",
    "\n",
    "                    else:\n",
    "                        dimensions = line.split(\":\")\n",
    "\n",
    "                        # If first row then note the number of dimensions (that must be the same for all cases)\n",
    "\n",
    "                        if is_first_case:\n",
    "                            num_dimensions = len(dimensions)\n",
    "\n",
    "                            if class_labels:\n",
    "                                num_dimensions -= 1\n",
    "\n",
    "                            for dim in range(0, num_dimensions):\n",
    "                                instance_list.append([])\n",
    "\n",
    "                            is_first_case = False\n",
    "\n",
    "                        # See how many dimensions that the case whose data in represented in this line has\n",
    "\n",
    "                        this_line_num_dimensions = len(dimensions)\n",
    "\n",
    "                        if class_labels:\n",
    "                            this_line_num_dimensions -= 1\n",
    "\n",
    "                        # All dimensions should be included for all series, even if they are empty\n",
    "\n",
    "                        if this_line_num_dimensions != num_dimensions:\n",
    "                            raise TsFileParseException(\"inconsistent number of dimensions\")\n",
    "\n",
    "                        # Process the data for each dimension\n",
    "\n",
    "                        for dim in range(0, num_dimensions):\n",
    "                            dimension = dimensions[dim].strip()\n",
    "\n",
    "                            if dimension:\n",
    "#                                 data_series = dimension.split(\",\")\n",
    "#                                 data_series = [float(i) for i in data_series]\n",
    "#                                 instance_list[dim].append(pd.Series(data_series))\n",
    "                                \n",
    "#                                 instance_list[dim].append(np.array(dimensions[dim].strip().split(','), dtype=np.float32))\n",
    "                                instance_list[dim].append(np.array(dimensions[dim].split(','), dtype=np.float32))\n",
    "#                                 instance_list[dim].append(np.fromiter(dimensions[dim].strip().split(','), dtype=np.float32))\n",
    "\n",
    "                            else:\n",
    "#                                 instance_list[dim].append(pd.Series())\n",
    "                                instance_list[dim].append([])\n",
    "\n",
    "                        if class_labels:\n",
    "                            class_val_list.append(dimensions[num_dimensions].strip())\n",
    "\n",
    "            line_num += 1\n",
    "\n",
    "    # Check that the file was not empty\n",
    "\n",
    "    if line_num:\n",
    "        # Check that the file contained both metadata and data\n",
    "\n",
    "        if metadata_started and not (has_problem_name_tag and has_timestamps_tag and has_univariate_tag and \n",
    "        has_class_labels_tag and has_data_tag):\n",
    "            raise TsFileParseException(\"metadata incomplete\")\n",
    "\n",
    "        elif metadata_started and not data_started:\n",
    "            raise TsFileParseException(\"file contained metadata but no data\")\n",
    "\n",
    "        elif metadata_started and data_started and len(instance_list) == 0:\n",
    "            raise TsFileParseException(\"file contained metadata but no data\")\n",
    "\n",
    "#         # Create a DataFrame from the data parsed above\n",
    "\n",
    "#         data = pd.DataFrame(dtype=np.float32)\n",
    "\n",
    "#         for dim in range(0, num_dimensions):\n",
    "#             data['dim_' + str(dim)] = instance_list[dim]\n",
    "\n",
    "#         # Check if we should return any associated class labels separately\n",
    "\n",
    "#         if class_labels:\n",
    "#             if return_separate_X_and_y:\n",
    "#                 return data, np.asarray(class_val_list)\n",
    "\n",
    "#             else:\n",
    "#                 data['class_vals'] = pd.Series(class_val_list)\n",
    "#                 return data\n",
    "#         else:\n",
    "#             return data\n",
    "\n",
    "        \n",
    "        # Create a numpy array\n",
    "            \n",
    "        #instance_list has a shape of (dimensions, nb_samples, seq_lenght)\n",
    "        #for the NATOPS_Train.arff it would be (24, 180, 51)\n",
    "        #convert python list to numpy array and traspose the 2 first dimensions -> (180, 24, 51)\n",
    "        data_array = np.asarray(instance_list).transpose(1,0,2) \n",
    "        y = np.asarray(class_val_list)\n",
    "\n",
    "        return data_array, y\n",
    "    \n",
    "\n",
    "    else:\n",
    "        raise TsFileParseException(\"empty file\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "Path('/home/farid/.fastai/data/NATOPS/NATOPS_TRAIN.ts')"
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fname_train = path_data/f'{dsname}/{dsname}_TRAIN.ts'\n",
    "fname_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "((180, 24, 51), (180,))"
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x_ts, train_y_ts = load_from_tsfile_to_array(fname_train)\n",
    "train_x_ts.shape, train_y_ts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "(24, 51)"
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x_ts[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "0.445743"
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x_ts[10][0][30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_UCR_univariate_list():\n",
    "    return [\n",
    "        'ACSF1', 'Adiac', 'AllGestureWiimoteX', 'AllGestureWiimoteY',\n",
    "        'AllGestureWiimoteZ', 'ArrowHead', 'Beef', 'BeetleFly', 'BirdChicken',\n",
    "        'BME', 'Car', 'CBF', 'Chinatown', 'ChlorineConcentration',\n",
    "        'CinCECGtorso', 'Coffee', 'Computers', 'CricketX', 'CricketY',\n",
    "        'CricketZ', 'Crop', 'DiatomSizeReduction',\n",
    "        'DistalPhalanxOutlineAgeGroup', 'DistalPhalanxOutlineCorrect',\n",
    "        'DistalPhalanxTW', 'DodgerLoopDay', 'DodgerLoopGame',\n",
    "        'DodgerLoopWeekend', 'Earthquakes', 'ECG200', 'ECG5000', 'ECGFiveDays',\n",
    "        'ElectricDevices', 'EOGHorizontalSignal', 'EOGVerticalSignal',\n",
    "        'EthanolLevel', 'FaceAll', 'FaceFour', 'FacesUCR', 'FiftyWords',\n",
    "        'Fish', 'FordA', 'FordB', 'FreezerRegularTrain', 'FreezerSmallTrain',\n",
    "        'Fungi', 'GestureMidAirD1', 'GestureMidAirD2', 'GestureMidAirD3',\n",
    "        'GesturePebbleZ1', 'GesturePebbleZ2', 'GunPoint', 'GunPointAgeSpan',\n",
    "        'GunPointMaleVersusFemale', 'GunPointOldVersusYoung', 'Ham',\n",
    "        'HandOutlines', 'Haptics', 'Herring', 'HouseTwenty', 'InlineSkate',\n",
    "        'InsectEPGRegularTrain', 'InsectEPGSmallTrain', 'InsectWingbeatSound',\n",
    "        'ItalyPowerDemand', 'LargeKitchenAppliances', 'Lightning2',\n",
    "        'Lightning7', 'Mallat', 'Meat', 'MedicalImages', 'MelbournePedestrian',\n",
    "        'MiddlePhalanxOutlineAgeGroup', 'MiddlePhalanxOutlineCorrect',\n",
    "        'MiddlePhalanxTW', 'MixedShapes', 'MixedShapesSmallTrain',\n",
    "        'MoteStrain', 'NonInvasiveFetalECGThorax1',\n",
    "        'NonInvasiveFetalECGThorax2', 'OliveOil', 'OSULeaf',\n",
    "        'PhalangesOutlinesCorrect', 'Phoneme', 'PickupGestureWiimoteZ',\n",
    "        'PigAirwayPressure', 'PigArtPressure', 'PigCVP', 'PLAID', 'Plane',\n",
    "        'PowerCons', 'ProximalPhalanxOutlineAgeGroup',\n",
    "        'ProximalPhalanxOutlineCorrect', 'ProximalPhalanxTW',\n",
    "        'RefrigerationDevices', 'Rock', 'ScreenType', 'SemgHandGenderCh2',\n",
    "        'SemgHandMovementCh2', 'SemgHandSubjectCh2', 'ShakeGestureWiimoteZ',\n",
    "        'ShapeletSim', 'ShapesAll', 'SmallKitchenAppliances', 'SmoothSubspace',\n",
    "        'SonyAIBORobotSurface1', 'SonyAIBORobotSurface2', 'StarlightCurves',\n",
    "        'Strawberry', 'SwedishLeaf', 'Symbols', 'SyntheticControl',\n",
    "        'ToeSegmentation1', 'ToeSegmentation2', 'Trace', 'TwoLeadECG',\n",
    "        'TwoPatterns', 'UMD', 'UWaveGestureLibraryAll', 'UWaveGestureLibraryX',\n",
    "        'UWaveGestureLibraryY', 'UWaveGestureLibraryZ', 'Wafer', 'Wine',\n",
    "        'WordSynonyms', 'Worms', 'WormsTwoClass', 'Yoga'\n",
    "    ]\n",
    "\n",
    "def get_UCR_multivariate_list():\n",
    "    return [\n",
    "        'ArticularyWordRecognition', 'AtrialFibrillation', 'BasicMotions',\n",
    "        'CharacterTrajectories', 'Cricket', 'DuckDuckGeese', 'EigenWorms',\n",
    "        'Epilepsy', 'EthanolConcentration', 'ERing', 'FaceDetection',\n",
    "        'FingerMovements', 'HandMovementDirection', 'Handwriting', 'Heartbeat',\n",
    "        'JapaneseVowels', 'Libras', 'LSST', 'InsectWingbeat', 'MotorImagery',\n",
    "        'NATOPS', 'PenDigits', 'PEMS-SF', 'PhonemeSpectra', 'RacketSports',\n",
    "        'SelfRegulationSCP1', 'SelfRegulationSCP2', 'SpokenArabicDigits',\n",
    "        'StandWalkJump', 'UWaveGestureLibrary'\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "_camel_re1 = re.compile('(.)([A-Z][a-z]+)')\n",
    "_camel_re2 = re.compile('([a-z0-9])([A-Z])')\n",
    "def camel2snake(name):\n",
    "    \"Convert CamelCase to snake_case\"\n",
    "    s1   = re.sub(_camel_re1, r'\\1_\\2', name)\n",
    "    return re.sub(_camel_re2, r'\\1_\\2', s1).lower()\n",
    "\n",
    "def camel2capitalsnake(name):\n",
    "    return camel2snake(name).upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "'ARTICULARY_WORD_RECOGNITION'"
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = 'ArticularyWordRecognition'\n",
    "s2 = camel2snake(s).upper()\n",
    "s2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# urls_ts = [f'{camel2capitalsnake(n)} = {n}.zip'     for n in get_UCR_multivariate_list()]\n",
    "# urls_ts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Converted 80_timeseries_data.ipynb.\nConverted 81_timeseries_core.ipynb.\nConverted Colab_timeseries_Tutorial.ipynb.\nConverted index.ipynb.\n"
    }
   ],
   "source": [
    "#hide\n",
    "from nbdev.export import notebook2script\n",
    "notebook2script()\n",
    "# notebook2script(fname='80_timeseries_data.ipynb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "converting: 80_timeseries_data.ipynb\n"
    },
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#hide\n",
    "from nbdev.export2html import _notebook2html\n",
    "# notebook2script()\n",
    "_notebook2html(fname='80_timeseries_data.ipynb')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://github.com/ai-fast-track/timeseries/blob/master/images/blue-sea.jpg?raw=1\" width=\"1440\" height=\"840\" alt=\"\"/>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
